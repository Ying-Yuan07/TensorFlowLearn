{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention-on-LSTM-for-effective-Recommendation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPuxet9mDfPYXoPF22FuSMa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ying-Yuan07/TensorFlowLearn/blob/main/Attention_on_LSTM_for_effective_Recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldBBiNmEZq8m",
        "outputId": "91d14e88-af7a-4fef-83c8-d435f25ae7bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras==2.1.6 in /usr/local/lib/python3.7/dist-packages (2.1.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.1.6) (1.5.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.1.6) (1.5.2)\n",
            "train_data.shape, test_data.shape\n",
            "(3000, 4) (1000, 4)\n",
            "item_seq_train.shape\n",
            "(2345,)\n",
            "item_seq_test.shape\n",
            "(824,)\n",
            "item_seq_test[0]\n",
            "['B0002JKPA4']\n",
            "item_test[0]\n",
            "['padding_id', 'padding_id', 'padding_id', 'padding_id', 'padding_id', 'B0002JKPA4']\n",
            "len(entire_products)\n",
            "1666\n",
            "train_x_emb.shape\n",
            "(2558, 5, 50)\n",
            "train_x.shape\n",
            "(2558, 5, 50)\n",
            "train_y\n",
            "(2558,)\n",
            "after one_hot train_y,total_vocab\n",
            "(2558, 4005)\n",
            "4005\n",
            "model is building\n",
            "Epoch 1/50\n",
            "2558/2558 [==============================] - 3s 1ms/step - loss: 8.2552 - acc: 0.0125\n",
            "Epoch 2/50\n",
            "2558/2558 [==============================] - 1s 196us/step - loss: 7.5127 - acc: 0.0195\n",
            "Epoch 3/50\n",
            "2558/2558 [==============================] - 0s 189us/step - loss: 7.0113 - acc: 0.0195\n",
            "Epoch 4/50\n",
            "2558/2558 [==============================] - 0s 194us/step - loss: 6.9442 - acc: 0.0195\n",
            "Epoch 5/50\n",
            "2558/2558 [==============================] - 1s 214us/step - loss: 6.9189 - acc: 0.0195\n",
            "Epoch 6/50\n",
            "2558/2558 [==============================] - 0s 193us/step - loss: 6.9039 - acc: 0.0195\n",
            "Epoch 7/50\n",
            "2558/2558 [==============================] - 0s 191us/step - loss: 6.8944 - acc: 0.0195\n",
            "Epoch 8/50\n",
            "2558/2558 [==============================] - 0s 190us/step - loss: 6.8862 - acc: 0.0195\n",
            "Epoch 9/50\n",
            "2558/2558 [==============================] - 1s 196us/step - loss: 6.8791 - acc: 0.0195\n",
            "Epoch 10/50\n",
            "2558/2558 [==============================] - 0s 183us/step - loss: 6.8755 - acc: 0.0195\n",
            "Epoch 11/50\n",
            "2558/2558 [==============================] - 0s 188us/step - loss: 6.8711 - acc: 0.0195\n",
            "Epoch 12/50\n",
            "2558/2558 [==============================] - 0s 183us/step - loss: 6.8669 - acc: 0.0195\n",
            "Epoch 13/50\n",
            "2558/2558 [==============================] - 0s 191us/step - loss: 6.8636 - acc: 0.0195\n",
            "Epoch 14/50\n",
            "2558/2558 [==============================] - 0s 192us/step - loss: 6.8613 - acc: 0.0195\n",
            "Epoch 15/50\n",
            "2558/2558 [==============================] - 0s 194us/step - loss: 6.8591 - acc: 0.0195\n",
            "Epoch 16/50\n",
            "2558/2558 [==============================] - 1s 225us/step - loss: 6.8552 - acc: 0.0195\n",
            "Epoch 17/50\n",
            "2558/2558 [==============================] - 1s 236us/step - loss: 6.8529 - acc: 0.0195\n",
            "Epoch 18/50\n",
            "2558/2558 [==============================] - 1s 201us/step - loss: 6.8521 - acc: 0.0195\n",
            "Epoch 19/50\n",
            "2558/2558 [==============================] - 1s 226us/step - loss: 6.8479 - acc: 0.0195\n",
            "Epoch 20/50\n",
            "2558/2558 [==============================] - 0s 193us/step - loss: 6.8452 - acc: 0.0195\n",
            "Epoch 21/50\n",
            "2558/2558 [==============================] - 0s 194us/step - loss: 6.8434 - acc: 0.0195\n",
            "Epoch 22/50\n",
            "2558/2558 [==============================] - 0s 193us/step - loss: 6.8397 - acc: 0.0195\n",
            "Epoch 23/50\n",
            "2558/2558 [==============================] - 1s 200us/step - loss: 6.8355 - acc: 0.0195\n",
            "Epoch 24/50\n",
            "2558/2558 [==============================] - 1s 197us/step - loss: 6.8292 - acc: 0.0195\n",
            "Epoch 25/50\n",
            "2558/2558 [==============================] - 0s 195us/step - loss: 6.8221 - acc: 0.0195\n",
            "Epoch 26/50\n",
            "2558/2558 [==============================] - 1s 196us/step - loss: 6.8126 - acc: 0.0195\n",
            "Epoch 27/50\n",
            "2558/2558 [==============================] - 0s 195us/step - loss: 6.7982 - acc: 0.0195\n",
            "Epoch 28/50\n",
            "2558/2558 [==============================] - 1s 196us/step - loss: 6.7822 - acc: 0.0195\n",
            "Epoch 29/50\n",
            "2558/2558 [==============================] - 0s 188us/step - loss: 6.7640 - acc: 0.0199\n",
            "Epoch 30/50\n",
            "2558/2558 [==============================] - 1s 196us/step - loss: 6.7420 - acc: 0.0199\n",
            "Epoch 31/50\n",
            "2558/2558 [==============================] - 0s 195us/step - loss: 6.7241 - acc: 0.0199\n",
            "Epoch 32/50\n",
            "2558/2558 [==============================] - 0s 191us/step - loss: 6.7086 - acc: 0.0203\n",
            "Epoch 33/50\n",
            "2558/2558 [==============================] - 0s 193us/step - loss: 6.6939 - acc: 0.0195\n",
            "Epoch 34/50\n",
            "2558/2558 [==============================] - 1s 196us/step - loss: 6.6813 - acc: 0.0199\n",
            "Epoch 35/50\n",
            "2558/2558 [==============================] - 1s 196us/step - loss: 6.6694 - acc: 0.0203\n",
            "Epoch 36/50\n",
            "2558/2558 [==============================] - 0s 195us/step - loss: 6.6591 - acc: 0.0195\n",
            "Epoch 37/50\n",
            "2558/2558 [==============================] - 0s 188us/step - loss: 6.6559 - acc: 0.0203\n",
            "Epoch 38/50\n",
            "2558/2558 [==============================] - 1s 199us/step - loss: 6.6441 - acc: 0.0207\n",
            "Epoch 39/50\n",
            "2558/2558 [==============================] - 1s 200us/step - loss: 6.6384 - acc: 0.0207\n",
            "Epoch 40/50\n",
            "2558/2558 [==============================] - 1s 197us/step - loss: 6.6361 - acc: 0.0207\n",
            "Epoch 41/50\n",
            "2558/2558 [==============================] - 0s 190us/step - loss: 6.6263 - acc: 0.0207\n",
            "Epoch 42/50\n",
            "2558/2558 [==============================] - 0s 191us/step - loss: 6.6202 - acc: 0.0207\n",
            "Epoch 43/50\n",
            "2558/2558 [==============================] - 0s 194us/step - loss: 6.6154 - acc: 0.0207\n",
            "Epoch 44/50\n",
            "2558/2558 [==============================] - 0s 189us/step - loss: 6.6110 - acc: 0.0207\n",
            "Epoch 45/50\n",
            "2558/2558 [==============================] - 1s 198us/step - loss: 6.6058 - acc: 0.0207\n",
            "Epoch 46/50\n",
            "2558/2558 [==============================] - 0s 192us/step - loss: 6.6005 - acc: 0.0207\n",
            "Epoch 47/50\n",
            "2558/2558 [==============================] - 0s 191us/step - loss: 6.5965 - acc: 0.0207\n",
            "Epoch 48/50\n",
            "2558/2558 [==============================] - 0s 191us/step - loss: 6.5908 - acc: 0.0211\n",
            "Epoch 49/50\n",
            "2558/2558 [==============================] - 0s 195us/step - loss: 6.5853 - acc: 0.0211\n",
            "Epoch 50/50\n",
            "2558/2558 [==============================] - 0s 194us/step - loss: 6.5807 - acc: 0.0211\n",
            "model building done\n",
            "pred\n",
            "[[1.3758737e-03 8.6857687e-04 4.5971724e-04 ... 2.0117420e-07\n",
            "  2.1791422e-07 2.3124069e-07]\n",
            " [1.2402473e-03 8.7895553e-04 4.7526523e-04 ... 4.8382458e-07\n",
            "  5.0133491e-07 5.2715461e-07]\n",
            " [1.3758737e-03 8.6857687e-04 4.5971724e-04 ... 2.0117420e-07\n",
            "  2.1791422e-07 2.3124069e-07]\n",
            " ...\n",
            " [1.3758737e-03 8.6857687e-04 4.5971724e-04 ... 2.0117419e-07\n",
            "  2.1791422e-07 2.3124069e-07]\n",
            " [1.3758737e-03 8.6857687e-04 4.5971724e-04 ... 2.0117420e-07\n",
            "  2.1791422e-07 2.3124069e-07]\n",
            " [1.3758737e-03 8.6857687e-04 4.5971724e-04 ... 2.0117419e-07\n",
            "  2.1791422e-07 2.3124069e-07]]\n",
            "pred.shape\n",
            "(422, 4005)\n",
            "preddy\n",
            "[ 293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            " 1114 1114  293 1114  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293   85  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293 1114\n",
            " 1114 1114 1114 1114 1114 1114 1114 1114 1114  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293   85  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293 1114 1114  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293 1114\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293   85  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293  293  293  293  293  293  293  293  293  293  293  293  293\n",
            "  293  293]\n",
            "preddy.shape\n",
            "(422,)\n",
            "0.002369668246445498\n",
            "0.004739336492890996\n",
            "predics10\n",
            "[array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([401,  18, 599, 408, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 85, 401, 471,  18,  92, 314,  55, 340, 464, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 437, 1011,  206,  140, 1091, 1033,  845,  192,  884, 1114]), array([1011,  540, 1091,  140,  206,  845, 1033,  192,  884, 1114]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 437,  845, 1011, 1033, 1091,  192,  140,  206,  884, 1114]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 602,   66, 1063,   92,  884, 1396,  707,  540,  505,   85]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([401,  85, 471,  18,  92, 314,  55, 340, 464, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 845, 1033,  437,  192, 1011, 1091,  884,  140,  206, 1114]), array([ 845, 1033,  437,  192, 1091, 1011,  884,  140,  206, 1114]), array([ 845, 1033,  192,  437, 1091, 1011,  884,  140,  206, 1114]), array([ 845, 1033,  192, 1091,  437, 1011,  884,  140,  206, 1114]), array([ 845, 1033,  192, 1091,  437,  884, 1011,  140,  206, 1114]), array([ 845, 1033,  192,  437, 1091, 1011,  884,  140,  206, 1114]), array([ 845, 1033,  192, 1091,  437,  884, 1011,  140,  206, 1114]), array([ 845, 1033,  437,  192, 1011, 1091,  884,  140,  206, 1114]), array([ 845, 1033,  192, 1091,  437, 1011,  884,  140,  206, 1114]), array([ 845, 1033,  192, 1091,  437, 1011,  884,  140,  206, 1114]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([401,  18, 599, 408, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([1052, 1396,   55,  707,  540,  293,   92,  464,  505,   85]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([1052,   18,  505,   85,  314,   92,  340,   55,  464,  293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 599, 401, 408, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 599, 401, 408, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 437, 1011,  206,  140, 1091, 1033,  845,  192,  884, 1114]), array([ 505,  602,  140,  206,  540,  845, 1033,  192,  884, 1114]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([471, 505,  18,  92,  85, 314, 340,  55, 464, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([1052,  540,  314,  340,   92,  505,   55,  464,   85,  293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([408, 401,  18, 471,  92, 314,  55, 340, 464, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 599, 401, 408, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 599, 401, 408, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 39, 401, 408,  18, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([  18, 1052,   92,  314,  505,  340,   55,   85,  464,  293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 845, 1033,  437,  192, 1011, 1091,  884,  140,  206, 1114]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 599, 401, 408, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([408, 401, 471,  18,  92, 314,  55, 340, 464, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([599, 401,  18, 408, 471, 314, 464,  55, 340, 293]), array([471,  18, 505,  92, 314,  85, 340,  55, 464, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 599, 401, 408, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 39, 401, 408,  18, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([1114, 1063,   66,  602,  707, 1396,  884,  540,  505,   85]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([471, 505,  18,  92,  85, 314, 340,  55, 464, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([599, 401,  18, 408, 471, 464, 314,  55, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 599, 401, 408, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([471, 505,  18,  92,  85, 314, 340,  55, 464, 293]), array([ 18, 599, 401, 408, 471, 464,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([707,  18, 314,  55, 540,  85, 464, 505,  92, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([505, 471,  18,  92,  85, 314, 340,  55, 464, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([1052,   18,  505,   92,  314,  340,   85,   55,  464,  293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293]), array([ 18, 606, 599, 464, 408, 471,  55, 314, 340, 293])]\n",
            "0.016587677725118485\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install keras==2.1.6\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from gensim.models import Word2Vec\n",
        "from keras.layers import Input,Dense,LSTM,Activation,RepeatVector,Permute,Flatten,Multiply\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model,Model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "np.random.seed(123)\n",
        "\n",
        "#Read data into pandas dataframe\n",
        "df=pd.read_csv('./sample_data/ratings_Beauty.csv')\n",
        "df=df[['UserId', 'ProductId','Rating','Timestamp']]\n",
        "\n",
        "#Rename the columns\n",
        "df.columns=['userid', 'item_id', 'rating', 'reviewTime']\n",
        "df=df.sort_values(['reviewTime'],ascending=[True])\n",
        "\n",
        "#Divide the train and test data\n",
        "#取数据0-1500行为训练集，1500-2000为测试集\n",
        "\n",
        "length=3000\n",
        "train_end = 4000\n",
        "train_data=df[:length]\n",
        "test_data=df[length:train_end]\n",
        "print(\"train_data.shape, test_data.shape\")\n",
        "print(train_data.shape, test_data.shape)\n",
        "train_data = train_data.reset_index()\n",
        "test_data = test_data.reset_index()\n",
        "    \n",
        "#find item sequences by user in train and test\n",
        "#按用户id排序，统计每个用户购买商品（item_id）的情况，将同一个用户购买的商品（item_id）放入同一个list，所有list组成一个array\n",
        "item_seq_train=train_data.groupby(\"userid\")['item_id'].apply(list).values\n",
        "item_seq_test=test_data.groupby(\"userid\")['item_id'].apply(list).values\n",
        "print(\"item_seq_train.shape\")\n",
        "print(item_seq_train.shape)\n",
        "print(\"item_seq_test.shape\")\n",
        "print(item_seq_test.shape)\n",
        "print(\"item_seq_test[0]\")\n",
        "print(item_seq_test[0])\n",
        "# We consider the minimum sequence length as 6. If length is less than 6, we append dummy ids to the sequence  \n",
        "# 一个用户购买商品数不足6个时，用'padding_id'填充到6个\n",
        "def min_six_len_seq(dictList):\n",
        "    new_list=[]\n",
        "    for i in range(0,len(dictList)):\n",
        "        if len(dictList[i])<6:\n",
        "            w=6-len(dictList[i])\n",
        "            dictList[i]=['padding_id']*w+dictList[i]\n",
        "    return dictList\n",
        "\n",
        "\n",
        "#find the train and test sequences of min len 6\n",
        "item_train = min_six_len_seq(item_seq_train)\n",
        "item_test = min_six_len_seq(item_seq_test)\n",
        "print(\"item_test[0]\")\n",
        "print(item_test[0])\n",
        "\n",
        "# train word2vec model on train_data to get item embeddings\n",
        "#Word2Vec(train_data,size,window,min_count,iter)\n",
        "#size是指词向量的维度，默认为100\n",
        "#min_count:要计算词向量的最小词频。这个值可以去掉一些很生僻的低频词，默认是5.可以对字典做截断， 词频少于min_count次数的单词会被丢弃掉\n",
        "#window:即词向量上下文最大距离,默认为5。window越大，则和某一词较远的词也会产生上下文关系，一般为[5,10]\n",
        "#iter: 随机梯度下降法中迭代的最大次数，默认是5。对于大语料，可以增大这个值\n",
        "#workers：用于控制训练的并行数。\n",
        "def word2vec_model(train_data):\n",
        "    model = Word2Vec(train_data,size=50,window = 3,min_count =1,iter=5)\n",
        "    return model\n",
        "\n",
        "\n",
        "#train the model and save\n",
        "wv_model=word2vec_model(item_train)\n",
        "wv_model.save('word2vec_model')\n",
        "\n",
        "#find full vocabulary\n",
        "entire_products=[]\n",
        "i = 0\n",
        "for key,value in wv_model.wv.vocab.items():\n",
        "    entire_products.append(key)\n",
        "np.save('./entire_products.npy',entire_products)\n",
        "print(\"len(entire_products)\")\n",
        "print(len(entire_products))\n",
        "\n",
        "\n",
        "# Divide the sequences into length of 6. ( First 5 items are for train, 6th one for target)\n",
        "#用5个历史购买商品预测下一个商品\n",
        "def input_sequences(new_list, win_size=5):\n",
        "    input_seq=[]\n",
        "    target=[]\n",
        "    for i in range(0,len(new_list)):\n",
        "        seq_len = len(new_list[i])\n",
        "        for j in range(0,seq_len):\n",
        "            if j+win_size<seq_len:\n",
        "                if new_list[i][j+5] in entire_products:\n",
        "                    input_seq.append(new_list[i][j:j+5])\n",
        "                    target.append(new_list[i][j+5])\n",
        "    return input_seq,target\n",
        "\n",
        "\n",
        "# Encoding the target.If new item arrives which i\n",
        "# 将目标商品列表target(原始数据是商品id)转换成商品词汇库中的序号\n",
        "def num_products(target):\n",
        "    product_label=LabelEncoder()\n",
        "    product_label.fit(entire_products)\n",
        "    target_int = product_label.transform(target)\n",
        "    return target_int\n",
        "    \n",
        "#Create Train and test input and target sequences\n",
        "#train_x:5个历史购买商品id list组成的arrary,train_y:目标商品在商品词汇库中对应的序号list\n",
        "train_x,target_train=input_sequences(item_seq_train)\n",
        "train_y=num_products(target_train)\n",
        "\n",
        "test_x,target_test=input_sequences(item_seq_test)\n",
        "test_y=num_products(target_test)\n",
        "    \n",
        "#represent each item with prod2vec embedding and if new item comes in test set, represent it with random vec\n",
        "#将train_x中的每一个商品id都映射成一个维度为50的向量\n",
        "unknown_item_id=np.random.random((50,))\n",
        "def w2v_data_extraction(new_list):\n",
        "    w2v_data=[]\n",
        "    for i in range(0,len(new_list)):\n",
        "        seq_vec=[]\n",
        "        for j in range(0,len(new_list[i])):\n",
        "            try:\n",
        "                embedding=wv_model.wv[new_list[i][j]]\n",
        "            except KeyError:\n",
        "                embedding=unknown_item_id\n",
        "            seq_vec.append(embedding)\n",
        "                \n",
        "        w2v_data.append(seq_vec)\n",
        "    return np.asarray(w2v_data)\n",
        "\n",
        "\n",
        "train_x_emb=w2v_data_extraction(train_x)\n",
        "test_x_emb=w2v_data_extraction(test_x)\n",
        "print(\"train_x_emb.shape\")\n",
        "print(train_x_emb.shape)\n",
        "#model architecture\n",
        "def model_arch():\n",
        "    main_input = Input(shape=(5,50), name='main_input')\n",
        "    lstm_out = LSTM(32)(main_input)\n",
        "    attention = Dense(1, activation='tanh')(lstm_out)\n",
        "    attention = Activation('softmax')(attention)\n",
        "    attention = RepeatVector(32)(attention)\n",
        "    attention = Permute([2, 1])(attention)\n",
        "    attention = Flatten()(attention)\n",
        "    attention_mul = Multiply()([lstm_out, attention])\n",
        "    main_output = (Dense(total_vocab, activation='softmax', name='main_output')(attention_mul))\n",
        "    model = Model(inputs=main_input, outputs=main_output)\n",
        "    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='ADAM')\n",
        "    return model\n",
        "\n",
        "\n",
        "#represent output as one-hot encoded\n",
        "def one_hot(seq,total_vocab):\n",
        "    seq_one_hot=np.zeros([len(seq),total_vocab])\n",
        "    for i in range(0,len(seq)):\n",
        "        seq_one_hot[i][seq[i]]=1\n",
        "    return seq_one_hot\n",
        "\n",
        "#fit the model on our data\n",
        "def model_fit(model,train_x,train_y,total_vocab):\n",
        "    print(\"train_x.shape\")\n",
        "    print(train_x.shape)\n",
        "    print(\"train_y\")\n",
        "    print(train_y.shape)\n",
        "    train_y=one_hot(train_y,total_vocab)\n",
        "    print(\"after one_hot train_y,total_vocab\")\n",
        "    print(train_y.shape)\n",
        "    print(total_vocab)\n",
        "\n",
        "    print(\"model is building\")\n",
        "    model.fit(batch_size=64,epochs=50,x=train_x,y=train_y)\n",
        "    print(\"model building done\")\n",
        "    model.save('keras_model.h5')\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "total_vocab=4005\n",
        "model = model_arch()\n",
        "model=model_fit(model,train_x_emb,train_y,total_vocab)\n",
        "\n",
        "# Hit rate at 1 on test data\n",
        "def hit_rate_at_1(prediction,actual):\n",
        "    return accuracy_score(prediction,actual)\n",
        "\n",
        "\n",
        "# Hit rata at 5 on test data\n",
        "def hit_rate_at_5(pred,actual):\n",
        "    predics = []\n",
        "    for i in range(0, len(pred)):\n",
        "        predics.append(np.argsort(pred[i])[-5:])\n",
        "    count = 0\n",
        "    for i in range(0, len(predics)):\n",
        "        if actual[i] in predics[i]:\n",
        "            count = count + 1\n",
        "\n",
        "    return count/len(actual)\n",
        "\n",
        "\n",
        "# Hit rate at 10 on test data\n",
        "def hit_rate_at_10(pred, actual):\n",
        "    predics = []\n",
        "    for i in range(0, len(pred)):\n",
        "        predics.append(np.argsort(pred[i])[-10:])\n",
        "    count = 0\n",
        "    print(\"predics10\")\n",
        "    print(predics)\n",
        "    for i in range(0, len(predics)):\n",
        "        if actual[i] in predics[i]:\n",
        "            count = count + 1\n",
        "    return count /len(actual)\n",
        "    \n",
        "# Prediction on test data\n",
        "def model_predict(model,test_x,test_seq):\n",
        "\n",
        "    pred=model.predict(x=test_x)\n",
        "    preddy=np.argmax(a=pred,axis=1)\n",
        "\n",
        "    print(\"pred\")\n",
        "    print(pred)\n",
        "    print(\"pred.shape\")\n",
        "    print(pred.shape)\n",
        "    print(\"preddy\")\n",
        "    print(preddy)\n",
        "    print(\"preddy.shape\")\n",
        "    print(preddy.shape)\n",
        "\n",
        "    print(hit_rate_at_1(preddy,test_seq))\n",
        "    print(hit_rate_at_5(pred, test_seq))\n",
        "    print(hit_rate_at_10(pred, test_seq))\n",
        "\n",
        "#predict on test data\n",
        "model_predict(model,test_x_emb,test_y)\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame( {'a':['A','A','B','B','F','C'], 'b':[1,2,5,5,4,6], 'c':[1,4,6,0,6,2]})\n",
        "print(df)\n",
        "ob = df.groupby('a')['b'].apply(list).values\n",
        "print(ob.shape)"
      ],
      "metadata": {
        "id": "bZ3lDrNFaabR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X7wqn87MbojL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
        "print(list(le.classes_))\n",
        "print(le.transform([\"tokyo\", \"tokyo\", \"paris\"]))\n",
        "print(list(le.inverse_transform([2, 2, 1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfAHdmY2zEPt",
        "outputId": "f886f76e-df65-460a-f9a8-5793c7ac1442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['amsterdam', 'paris', 'tokyo']\n",
            "[2 2 1]\n",
            "['tokyo', 'tokyo', 'paris']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "id": "fZ_NhomBMIFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([3, 1, 2, 4, 6, 1])\n",
        "print(np.argmax(a))"
      ],
      "metadata": {
        "id": "HYAu50EiQ9c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([[1, 5, 5, 2],\n",
        "        [9, 6, 2, 8],\n",
        "        [3, 7, 9, 1]])\n",
        "print(np.argmax(a, axis=0))"
      ],
      "metadata": {
        "id": "om2XVX0IRDRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([[1, 5, 5, 2],\n",
        "        [9, 6, 2, 8],\n",
        "        [3, 7, 9, 1]])\n",
        "print(np.argmax(a, axis=1))"
      ],
      "metadata": {
        "id": "jmsfT6AqRNSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}