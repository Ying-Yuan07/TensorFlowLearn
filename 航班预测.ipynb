{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "航班预测.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMw5dw8wCWu+sbjs/NbWZ4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ying-Yuan07/TensorFlowLearn/blob/main/%E8%88%AA%E7%8F%AD%E9%A2%84%E6%B5%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JAaJmk-5TP_y",
        "outputId": "55d6872b-24ca-4dcd-92d7-c735a944f84d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "values original:\n",
            "\n",
            "[[86.0 -11 -9.0 1020.0 'SE' 124.71 22 0]\n",
            " [70.0 -11 -9.0 1020.0 'SE' 127.84 23 0]\n",
            " [61.0 -11 -9.0 1021.0 'cv' 0.89 24 0]\n",
            " [53.0 -11 -9.0 1022.0 'cv' 1.78 25 0]\n",
            " [71.0 -10 -9.0 1022.0 'NW' 4.02 26 0]\n",
            " [72.0 -11 -10.0 1023.0 'NW' 7.15 27 0]\n",
            " [76.0 -11 -9.0 1023.0 'NW' 11.17 0 0]\n",
            " [73.0 -12 -11.0 1023.0 'NW' 14.3 0 0]\n",
            " [79.0 -14 -12.0 1023.0 'NW' 16.09 0 0]\n",
            " [58.0 -16 -9.0 1023.0 'NW' 21.9 0 0]]\n",
            "values encoded:\n",
            "\n",
            "[[ 8.6000e+01 -1.1000e+01 -9.0000e+00  1.0200e+03  2.0000e+00  1.2471e+02\n",
            "   2.2000e+01  0.0000e+00]\n",
            " [ 7.0000e+01 -1.1000e+01 -9.0000e+00  1.0200e+03  2.0000e+00  1.2784e+02\n",
            "   2.3000e+01  0.0000e+00]\n",
            " [ 6.1000e+01 -1.1000e+01 -9.0000e+00  1.0210e+03  3.0000e+00  8.9000e-01\n",
            "   2.4000e+01  0.0000e+00]\n",
            " [ 5.3000e+01 -1.1000e+01 -9.0000e+00  1.0220e+03  3.0000e+00  1.7800e+00\n",
            "   2.5000e+01  0.0000e+00]\n",
            " [ 7.1000e+01 -1.0000e+01 -9.0000e+00  1.0220e+03  1.0000e+00  4.0200e+00\n",
            "   2.6000e+01  0.0000e+00]\n",
            " [ 7.2000e+01 -1.1000e+01 -1.0000e+01  1.0230e+03  1.0000e+00  7.1500e+00\n",
            "   2.7000e+01  0.0000e+00]\n",
            " [ 7.6000e+01 -1.1000e+01 -9.0000e+00  1.0230e+03  1.0000e+00  1.1170e+01\n",
            "   0.0000e+00  0.0000e+00]\n",
            " [ 7.3000e+01 -1.2000e+01 -1.1000e+01  1.0230e+03  1.0000e+00  1.4300e+01\n",
            "   0.0000e+00  0.0000e+00]\n",
            " [ 7.9000e+01 -1.4000e+01 -1.2000e+01  1.0230e+03  1.0000e+00  1.6090e+01\n",
            "   0.0000e+00  0.0000e+00]\n",
            " [ 5.8000e+01 -1.6000e+01 -9.0000e+00  1.0230e+03  1.0000e+00  2.1900e+01\n",
            "   0.0000e+00  0.0000e+00]]\n",
            "values scaled:\n",
            "\n",
            "[[8.65191147e-02 4.26470608e-01 1.63934425e-01 5.27273178e-01\n",
            "  6.66666687e-01 2.12355822e-01 8.14814806e-01 0.00000000e+00]\n",
            " [7.04225302e-02 4.26470608e-01 1.63934425e-01 5.27273178e-01\n",
            "  6.66666687e-01 2.17704877e-01 8.51851881e-01 0.00000000e+00]\n",
            " [6.13682084e-02 4.26470608e-01 1.63934425e-01 5.45454025e-01\n",
            "  1.00000000e+00 7.51943968e-04 8.88888896e-01 0.00000000e+00]\n",
            " [5.33199161e-02 4.26470608e-01 1.63934425e-01 5.63636780e-01\n",
            "  1.00000000e+00 2.27292161e-03 9.25925910e-01 0.00000000e+00]\n",
            " [7.14285672e-02 4.41176474e-01 1.63934425e-01 5.63636780e-01\n",
            "  3.33333343e-01 6.10100012e-03 9.62962985e-01 0.00000000e+00]\n",
            " [7.24346042e-02 4.26470608e-01 1.47540987e-01 5.81817627e-01\n",
            "  3.33333343e-01 1.14500560e-02 1.00000000e+00 0.00000000e+00]\n",
            " [7.64587522e-02 4.26470608e-01 1.63934425e-01 5.81817627e-01\n",
            "  3.33333343e-01 1.83200892e-02 0.00000000e+00 0.00000000e+00]\n",
            " [7.34406412e-02 4.11764741e-01 1.31147534e-01 5.81817627e-01\n",
            "  3.33333343e-01 2.36691460e-02 0.00000000e+00 0.00000000e+00]\n",
            " [7.94768557e-02 3.82352948e-01 1.14754096e-01 5.81817627e-01\n",
            "  3.33333343e-01 2.67281905e-02 0.00000000e+00 0.00000000e+00]\n",
            " [5.83500974e-02 3.52941215e-01 1.63934425e-01 5.81817627e-01\n",
            "  3.33333343e-01 3.66572700e-02 0.00000000e+00 0.00000000e+00]]\n",
            "       var1(t-3)  var2(t-3)  var3(t-3)  var4(t-3)  var5(t-3)  var6(t-3)  var7(t-3)  var8(t-3)  var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var6(t-2)  var7(t-2)  var8(t-2)  var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  var7(t-1)  var8(t-1)   var1(t)   var2(t)   var3(t)   var4(t)   var5(t)   var6(t)   var7(t)  var8(t)\n",
            "0            NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN  0.129779  0.352941  0.245902  0.527273  0.666667  0.002290  0.000000      0.0\n",
            "1            NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   0.000000        0.0  0.148893  0.367647  0.245902  0.527273  0.666667  0.003811  0.000000      0.0\n",
            "2            NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290        0.0        0.0   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   0.000000        0.0  0.159960  0.426471  0.229508  0.545454  0.666667  0.005332  0.000000      0.0\n",
            "3       0.129779   0.352941   0.245902   0.527273   0.666667   0.002290        0.0        0.0   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811        0.0        0.0   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   0.000000        0.0  0.182093  0.485294  0.229508  0.563637  0.666667  0.008391  0.037037      0.0\n",
            "4       0.148893   0.367647   0.245902   0.527273   0.666667   0.003811        0.0        0.0   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332        0.0        0.0   0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   0.037037        0.0  0.138833  0.485294  0.229508  0.563637  0.666667  0.009912  0.074074      0.0\n",
            "...          ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...       ...       ...       ...       ...       ...       ...       ...      ...\n",
            "43795   0.008048   0.250000   0.311475   0.745455   0.333333   0.365103        0.0        0.0   0.009054   0.264706   0.295082   0.763638   0.333333   0.377322        0.0        0.0   0.010060   0.264706   0.278689   0.763638   0.333333   0.385730   0.000000        0.0  0.008048  0.250000  0.278689  0.781818  0.333333  0.395659  0.000000      0.0\n",
            "43796   0.009054   0.264706   0.295082   0.763638   0.333333   0.377322        0.0        0.0   0.010060   0.264706   0.278689   0.763638   0.333333   0.385730        0.0        0.0   0.008048   0.250000   0.278689   0.781818   0.333333   0.395659   0.000000        0.0  0.010060  0.264706  0.262295  0.781818  0.333333  0.405588  0.000000      0.0\n",
            "43797   0.010060   0.264706   0.278689   0.763638   0.333333   0.385730        0.0        0.0   0.008048   0.250000   0.278689   0.781818   0.333333   0.395659        0.0        0.0   0.010060   0.264706   0.262295   0.781818   0.333333   0.405588   0.000000        0.0  0.010060  0.264706  0.262295  0.781818  0.333333  0.413996  0.000000      0.0\n",
            "43798   0.008048   0.250000   0.278689   0.781818   0.333333   0.395659        0.0        0.0   0.010060   0.264706   0.262295   0.781818   0.333333   0.405588        0.0        0.0   0.010060   0.264706   0.262295   0.781818   0.333333   0.413996   0.000000        0.0  0.008048  0.264706  0.245902  0.781818  0.333333  0.420866  0.000000      0.0\n",
            "43799   0.010060   0.264706   0.262295   0.781818   0.333333   0.405588        0.0        0.0   0.010060   0.264706   0.262295   0.781818   0.333333   0.413996        0.0        0.0   0.008048   0.264706   0.245902   0.781818   0.333333   0.420866   0.000000        0.0  0.012072  0.279412  0.262295  0.781818  0.333333  0.426216  0.000000      0.0\n",
            "\n",
            "[43800 rows x 32 columns]\n",
            "(43797, 32)\n",
            "(8760, 24) 8760 (8760,)\n",
            "(8760, 3, 8) (8760,) (35037, 3, 8) (35037,)\n",
            "Epoch 1/50\n",
            "122/122 - 4s - loss: 0.0524 - val_loss: 0.0690 - 4s/epoch - 30ms/step\n",
            "Epoch 2/50\n",
            "122/122 - 2s - loss: 0.0273 - val_loss: 0.0504 - 2s/epoch - 14ms/step\n",
            "Epoch 3/50\n",
            "122/122 - 2s - loss: 0.0225 - val_loss: 0.0312 - 2s/epoch - 13ms/step\n",
            "Epoch 4/50\n",
            "122/122 - 1s - loss: 0.0216 - val_loss: 0.0257 - 999ms/epoch - 8ms/step\n",
            "Epoch 5/50\n",
            "122/122 - 2s - loss: 0.0211 - val_loss: 0.0228 - 2s/epoch - 13ms/step\n",
            "Epoch 6/50\n",
            "122/122 - 1s - loss: 0.0206 - val_loss: 0.0211 - 985ms/epoch - 8ms/step\n",
            "Epoch 7/50\n",
            "122/122 - 2s - loss: 0.0201 - val_loss: 0.0209 - 2s/epoch - 13ms/step\n",
            "Epoch 8/50\n",
            "122/122 - 1s - loss: 0.0200 - val_loss: 0.0195 - 1s/epoch - 9ms/step\n",
            "Epoch 9/50\n",
            "122/122 - 1s - loss: 0.0192 - val_loss: 0.0200 - 1s/epoch - 8ms/step\n",
            "Epoch 10/50\n",
            "122/122 - 1s - loss: 0.0189 - val_loss: 0.0201 - 979ms/epoch - 8ms/step\n",
            "Epoch 11/50\n",
            "122/122 - 2s - loss: 0.0186 - val_loss: 0.0197 - 2s/epoch - 13ms/step\n",
            "Epoch 12/50\n",
            "122/122 - 1s - loss: 0.0179 - val_loss: 0.0191 - 939ms/epoch - 8ms/step\n",
            "Epoch 13/50\n",
            "122/122 - 1s - loss: 0.0176 - val_loss: 0.0182 - 976ms/epoch - 8ms/step\n",
            "Epoch 14/50\n",
            "122/122 - 2s - loss: 0.0172 - val_loss: 0.0178 - 2s/epoch - 14ms/step\n",
            "Epoch 15/50\n",
            "122/122 - 2s - loss: 0.0167 - val_loss: 0.0175 - 2s/epoch - 13ms/step\n",
            "Epoch 16/50\n",
            "122/122 - 2s - loss: 0.0165 - val_loss: 0.0170 - 2s/epoch - 13ms/step\n",
            "Epoch 17/50\n",
            "122/122 - 1s - loss: 0.0162 - val_loss: 0.0170 - 981ms/epoch - 8ms/step\n",
            "Epoch 18/50\n",
            "122/122 - 1s - loss: 0.0159 - val_loss: 0.0164 - 959ms/epoch - 8ms/step\n",
            "Epoch 19/50\n",
            "122/122 - 2s - loss: 0.0156 - val_loss: 0.0163 - 2s/epoch - 13ms/step\n",
            "Epoch 20/50\n",
            "122/122 - 1s - loss: 0.0153 - val_loss: 0.0170 - 950ms/epoch - 8ms/step\n",
            "Epoch 21/50\n",
            "122/122 - 2s - loss: 0.0152 - val_loss: 0.0171 - 2s/epoch - 13ms/step\n",
            "Epoch 22/50\n",
            "122/122 - 1s - loss: 0.0149 - val_loss: 0.0173 - 935ms/epoch - 8ms/step\n",
            "Epoch 23/50\n",
            "122/122 - 1s - loss: 0.0148 - val_loss: 0.0174 - 945ms/epoch - 8ms/step\n",
            "Epoch 24/50\n",
            "122/122 - 1s - loss: 0.0146 - val_loss: 0.0171 - 968ms/epoch - 8ms/step\n",
            "Epoch 25/50\n",
            "122/122 - 1s - loss: 0.0146 - val_loss: 0.0174 - 977ms/epoch - 8ms/step\n",
            "Epoch 26/50\n",
            "122/122 - 2s - loss: 0.0146 - val_loss: 0.0174 - 2s/epoch - 13ms/step\n",
            "Epoch 27/50\n",
            "122/122 - 1s - loss: 0.0145 - val_loss: 0.0171 - 986ms/epoch - 8ms/step\n",
            "Epoch 28/50\n",
            "122/122 - 1s - loss: 0.0145 - val_loss: 0.0169 - 1s/epoch - 8ms/step\n",
            "Epoch 29/50\n",
            "122/122 - 1s - loss: 0.0145 - val_loss: 0.0173 - 902ms/epoch - 7ms/step\n",
            "Epoch 30/50\n",
            "122/122 - 1s - loss: 0.0145 - val_loss: 0.0158 - 873ms/epoch - 7ms/step\n",
            "Epoch 31/50\n",
            "122/122 - 1s - loss: 0.0145 - val_loss: 0.0156 - 1s/epoch - 8ms/step\n",
            "Epoch 32/50\n",
            "122/122 - 1s - loss: 0.0144 - val_loss: 0.0151 - 998ms/epoch - 8ms/step\n",
            "Epoch 33/50\n",
            "122/122 - 1s - loss: 0.0144 - val_loss: 0.0151 - 1s/epoch - 8ms/step\n",
            "Epoch 34/50\n",
            "122/122 - 2s - loss: 0.0145 - val_loss: 0.0146 - 2s/epoch - 13ms/step\n",
            "Epoch 35/50\n",
            "122/122 - 1s - loss: 0.0144 - val_loss: 0.0148 - 1s/epoch - 8ms/step\n",
            "Epoch 36/50\n",
            "122/122 - 1s - loss: 0.0145 - val_loss: 0.0145 - 1s/epoch - 8ms/step\n",
            "Epoch 37/50\n",
            "122/122 - 2s - loss: 0.0143 - val_loss: 0.0147 - 2s/epoch - 14ms/step\n",
            "Epoch 38/50\n",
            "122/122 - 1s - loss: 0.0144 - val_loss: 0.0151 - 1s/epoch - 9ms/step\n",
            "Epoch 39/50\n",
            "122/122 - 2s - loss: 0.0145 - val_loss: 0.0142 - 2s/epoch - 14ms/step\n",
            "Epoch 40/50\n",
            "122/122 - 1s - loss: 0.0144 - val_loss: 0.0140 - 979ms/epoch - 8ms/step\n",
            "Epoch 41/50\n",
            "122/122 - 1s - loss: 0.0142 - val_loss: 0.0146 - 1s/epoch - 8ms/step\n",
            "Epoch 42/50\n",
            "122/122 - 1s - loss: 0.0144 - val_loss: 0.0143 - 958ms/epoch - 8ms/step\n",
            "Epoch 43/50\n",
            "122/122 - 2s - loss: 0.0143 - val_loss: 0.0140 - 2s/epoch - 13ms/step\n",
            "Epoch 44/50\n",
            "122/122 - 1s - loss: 0.0143 - val_loss: 0.0144 - 1s/epoch - 8ms/step\n",
            "Epoch 45/50\n",
            "122/122 - 1s - loss: 0.0143 - val_loss: 0.0140 - 1s/epoch - 8ms/step\n",
            "Epoch 46/50\n",
            "122/122 - 2s - loss: 0.0142 - val_loss: 0.0142 - 2s/epoch - 13ms/step\n",
            "Epoch 47/50\n",
            "122/122 - 2s - loss: 0.0143 - val_loss: 0.0138 - 2s/epoch - 13ms/step\n",
            "Epoch 48/50\n",
            "122/122 - 1s - loss: 0.0142 - val_loss: 0.0140 - 974ms/epoch - 8ms/step\n",
            "Epoch 49/50\n",
            "122/122 - 2s - loss: 0.0143 - val_loss: 0.0140 - 2s/epoch - 14ms/step\n",
            "Epoch 50/50\n",
            "122/122 - 2s - loss: 0.0142 - val_loss: 0.0140 - 2s/epoch - 14ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 26.455\n"
          ]
        }
      ],
      "source": [
        "from math import sqrt\n",
        "from numpy import concatenate\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import pandas as pd\n",
        "\n",
        "\"\"\"\n",
        "本文是LSTM多元预测\n",
        "用3个步长的数据预测1个步长的数据\n",
        "包含：\n",
        "对数据进行缩放，缩放格式为n行*8列，因为数据没有季节性，所以不做差分\n",
        "对枚举列（风向）进行数字编码\n",
        "构造3->1的监督学习数据\n",
        "构造网络开始预测\n",
        "将预测结果重新拼接为n行*8列数据\n",
        "数据逆缩放，求RSME误差\n",
        "\"\"\"\n",
        "pd.set_option('display.max_columns',1000)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_colwidth',1000)\n",
        "\n",
        "# 转换成监督数据，四列数据，3->1，三组预测一组\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1] #列数\n",
        "    df = DataFrame(data) #用归一化之后的excel数据构造 DataFrame\n",
        "    cols, names = list(), list()#创建空list\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    # 将3组输入数据依次向下移动3，2，1行，将数据加入cols列表（技巧：(n_in, 0, -1)中的-1指倒序循环，步长为1）\n",
        "    for i in range(n_in, 0, -1):\n",
        "    \tcols.append(df.shift(i))\n",
        "    \tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    # 将一组输出数据加入cols列表（技巧：其中i=0）\n",
        "    for i in range(0, n_out):\n",
        "    \tcols.append(df.shift(-i))\n",
        "    \tif i == 0:\n",
        "    \t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "    \telse:\n",
        "    \t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # cols列表(list)中现在有四块经过下移后的数据(即：df(-3),df(-2),df(-1),df)，将四块数据按列 并排合并\n",
        "    agg = concat(cols, axis=1)\n",
        "    # 给合并后的数据添加列名\n",
        "    agg.columns = names\n",
        "    print(agg)\n",
        "    # 删除NaN值列\n",
        "    if dropnan:\n",
        "    \tagg.dropna(inplace=True)\n",
        "    return agg\n",
        "\n",
        "# load dataset\n",
        "dataset = read_csv('./sample_data/pollution.csv', header=0, index_col=0)\n",
        "values = dataset.values\n",
        "print(\"values original:\\n\")\n",
        "print(values[40:50,:])\n",
        "\n",
        "# 对“风向”列进行整数编码\n",
        "encoder = LabelEncoder()\n",
        "values[:,4] = encoder.fit_transform(values[:,4])\n",
        "values = values.astype('float32')\n",
        "print(\"values encoded:\\n\")\n",
        "print(values[40:50,:])\n",
        "\n",
        "# 标准化/放缩 特征值在（0,1）之间\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(values)\n",
        "print(\"values scaled:\\n\")\n",
        "print(scaled[40:50,:])\n",
        "\n",
        "# 用3小时数据预测一小时数据，8个特征值\n",
        "n_hours = 3\n",
        "n_features = 8\n",
        "# 构造一个3->1的监督学习型数据\n",
        "reframed = series_to_supervised(scaled, n_hours, 1)\n",
        "print(reframed.shape)\n",
        "\n",
        "# split into train and test sets\n",
        "values = reframed.values\n",
        "# 用一年的数据来训练\n",
        "n_train_hours = 365 * 24\n",
        "train = values[:n_train_hours, :]\n",
        "test = values[n_train_hours:, :]\n",
        "# split into input and outputs\n",
        "n_obs = n_hours * n_features\n",
        "# 有32=(4*8)列数据，取前24=(3*8) 列作为X，倒数第8列=(第25列)作为Y\n",
        "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
        "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
        "print(train_X.shape, len(train_X), train_y.shape)\n",
        "# 将数据转换为3D输入，timesteps=3，3条数据预测1条 [samples, timesteps, features]\n",
        "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
        "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
        "\n",
        "# 设计网络\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mae', optimizer='adam')\n",
        "# 拟合网络\n",
        "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "\n",
        "# 执行预测\n",
        "yhat = model.predict(test_X)\n",
        "# 将数据格式化成 n行 * 24列\n",
        "test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n",
        "# 将预测列据和后7列数据拼接，因后续逆缩放时，数据形状要符合 n行*8列 的要求\n",
        "inv_yhat = concatenate((yhat, test_X[:, -7:]), axis=1)\n",
        "# 对拼接好的数据进行逆缩放\n",
        "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "inv_yhat = inv_yhat[:,0]\n",
        "\n",
        "test_y = test_y.reshape((len(test_y), 1))\n",
        "# 将真实列据和后7列数据拼接，因后续逆缩放时，数据形状要符合 n行*8列 的要求\n",
        "inv_y = concatenate((test_y, test_X[:, -7:]), axis=1)\n",
        "# 对拼接好的数据进行逆缩放\n",
        "inv_y = scaler.inverse_transform(inv_y)\n",
        "inv_y = inv_y[:,0]\n",
        "\n",
        "# 计算RMSE误差值\n",
        "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xzAaqKiIhH-x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}